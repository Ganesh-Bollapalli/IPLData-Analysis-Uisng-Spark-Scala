

------------- Five Players with Most Man Of the Match awards -----------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.groupBy("Player of the match").count()
df1.sort(desc("count")).limit(5).show()


------------- Avg first innings score of Eaden Gardens ---------------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1 = df.groupBy("Venue").agg(avg("First innings score").alias("Avg 1st ing score"))
df1.filter(df1("Venue").like("E%")).show()


-------------- Teams with most wins and losses -----------------------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.groupBy("Match winner").count()
df1.sort(desc("count")).show()


-------------- Teams with most ipl thropies  -------------------------------------------------

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.na.fill("NA")
val df2=df1.withColumn("Stage", df1("Stage").cast("String"))
df2.filter(df2("Stage")=="Final").show()
val df3=df2.filter(df2("Stage").like("Final"))
val df4=df3.groupBy("Match winner").count
df4.withColumnRenamed("count", "IPL Trophies").sort(desc("IPL Trophies")).show()


---------------- No of matches placed between Chennai and Mumbai ----------------------------

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.na.fill("NA")
val df2=df1.filter(df1("Team1") === "Chennai Super Kings" && df1("Team2") === "Mumbai Indians")
val df3=df1.filter(df1("Team1") === "Mumbai Indians" && df1("Team2") === "Chennai Super Kings")
println(df3.count+df2.count)

----------------- Highest score and lowest score of IPL fitst & second innings ------------------

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.na.fill("NA")
val df1=df.withColumn("First innings score", df("First innings score").cast("Int"))
df1.groupBy().agg(max("First innings score").alias("Highest Score")).show()
val df1=df.withColumn("Second innings score", df("Second innings score").cast("Int"))
df1.groupBy().agg(max("Second innings score").alias("Highest Score")).show()        (or) ***df1.agg(max("Second innings score").alias("Highest Score")).show()***

val df2=df1.withColumn("First innings score", when(df1("First innings score") ===0, 150).otherwise(df1("First innings score")))
df2.agg(min("First innings score").alias("Lowest Score")).show()


val df2=df1.withColumn("Second innings score", when(df1("Second innings score") ===0, 150).otherwise(df1("Second innings score")))
df2.agg(min("Second innings score").alias("Lowest Score")).show()

------------------------ Most Toss winners -----------------------------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.groupBy("Toss winner").count()
df1.sort(desc("count")).show()

------------------------ Teams choosed first batting won ----------------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.filter(df("Toss decision") === "Bat").filter(df("Toss winner") === df("Match winner"))
df1.count
val df1=df.filter(df("Toss decision") === "Field").filter(df("Toss winner") === df("Match winner"))
df1.count
val df1=df.filter(df("Toss decision") === "Bat").filter(df("Toss winner")!== df("Match winner"))
df1.count
val df1=df.filter(df("Toss decision") === "Field").filter(df("Toss winner") !== df("Match winner"))
df1.count

----------------------- Matches played by kkr ---------------------------------------------------

import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()

val df = spark.read.option("header","True").csv("ipldata.csv")
val df1=df.filter(df("Team1").like("Kolkata Knight Riders"))
val df2=df.filter(df("Team2").like("Kolkata Knight Riders"))
println(df1.count+df2.count)

-------------------------------------------------------------------------------------------------